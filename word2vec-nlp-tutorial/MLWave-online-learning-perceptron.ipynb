{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Online Learning Perceptron From MLWave](https://mlwave.com/online-learning-perceptron/)\n",
    "\n",
    "* 온라인 학습 퍼셉트론\n",
    "\n",
    "* 퍼셉트론 : 가장 단순한 인공신경망을 본다. 이 기사는 1943년에 고안된 개념에서 2015년 Kaggle 경진대회로 옮겨간다. NLP 감정 분석 작업에서 하나의 인공 신경 세포가 0.95 AUC를 얻을 수 있음을 보여준다.(영화 리뷰가 긍정인지 부정인지 예측)\n",
    "\n",
    "McCulloch-Pitts Neuron\n",
    "인공 신경망의 탄생은 1943 년의 논문 “a Logical Calculus of the Ideas Immanent in Nervous Activity”. 으로 시작되었다. 신경 학자 인 McCulloch는 논리학자인 Pitts라는 두 연구자가 최초의 인공 뉴런을 스케치하기 위해 힘을 합쳤다.\n",
    "\n",
    "\n",
    "McCulloch는 신경 활동에 ‘all-or-nothing’활동이 있다고 추론했다. 활성화 임계 값에 도달하거나(출력 1) 출력하지 않으면 (출력 0) 신경세포가 발화한다.\n",
    "피츠 (Pitts)는 그러한 신경 학적 원칙을 사용하여 명제 논리를 포착 할 수있는 잠재력을보고 이해했다.\n",
    "\n",
    "<img src='https://mlwave.com/wp-content/uploads/2015/01/mccullogpitts.png'>\n",
    "McCulloch-Pitts 논문에서 뉴런의 회로도, looping 뉴런과 net\n",
    "\n",
    "새가 씨앗과 같이 작은 물체를 먹으려고 한다. 이 행동을 표로 나타내면 다음과 같다.\n",
    "\n",
    "\n",
    "\n",
    "|OBJECT|BROWN?|\tROUND?|\tEAT?|\n",
    "|:---|:---:|---:|:---|\n",
    "|Seed|\t1|\t1|\t1|\n",
    "|Leaf|\t1|\t0|\t0|\n",
    "|Golf Ball|\t0|\t1|\t0|\n",
    "|Key|\t0|\t0|\t0|\n",
    "\n",
    "McCulloch-Pitts Neuron으로 위 표를 모델링 할 수 있다. 활성화 임계 값을 1.5로 설정하면 \"BROWN\"및 \"ROUND\"속성이 모두 충족 될 때만 뉴런이 실행된다. 그러면 입력 합계는 2 (1 + 1)로 1.5의 활성화 임계 값보다 크다.\n",
    "\n",
    "<img src='https://mlwave.com/wp-content/uploads/2015/01/pitts-neuron.png'>\n",
    "\n",
    "### Learning\n",
    "\n",
    "퍼셉트론은 지도학습 분류기의 일종이다. 이전 값에 대한 학습으로 예측을 한다.\n",
    "내적(dotproduct) 값이 임계 값보다 높거나 낮은지에 따라 초과하면 \"1\"을 예측하고 미만이면 \"0\"을 예측한다.\n",
    "\n",
    "다음 perceptron은 샘플의 레이블을 봅니다. 예측이 정확하다면, 오류는 \"0\"이며, 가중치만 남겨 둔다. 예측이 틀린 경우 오류는 \"-1\"또는 \"1\"이고 퍼셉트론은 다음과 같이 가중치를 업데이트합니다.\n",
    "\n",
    "`weights[feature_index] += learning_rate * error * feature_value`\n",
    "\n",
    "\n",
    "## 퍼셉트론\n",
    "출처 : [퍼셉트론 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0)\n",
    "\n",
    "\n",
    "인식 심리학자 Frank Rosenblatt가 1957 년에 발명 한 퍼셉트론 알고리즘은 하드웨어로 구현 된 최초의 인공 신경망이었다.\n",
    "\n",
    "퍼셉트론(perceptron)은 인공신경망의 한 종류로서, 1957년에 코넬 항공 연구소(Cornell Aeronautical Lab)의 프랑크 로젠블라트 (Frank Rosenblatt)에 의해 고안되었다. 이것은 가장 간단한 형태의 피드포워드(Feedforward) 네트워크 - 선형분류기- 으로도 볼 수 있다.\n",
    "\n",
    "1960년 코넬 항공 연구소의 연구원은 미 해군 연구청의 자금으로 무작위로 400개의 광전지를 하나의 퍼셉트론에 연결하여 \"마크 1 퍼셉트론 (Mark 1 perceptron)\"이 탄생해 이것으로 기본 이미지 인식이 가능했다.\n",
    "\n",
    "퍼셉트론이 동작하는 방식은 다음과 같다. 각 노드의 가중치와 입력치를 곱한 것을 모두 합한 값이 활성함수에 의해 판단되는데, 그 값이 임계치(보통 0)보다 크면 뉴런이 활성화되고 결과값으로 1을 출력한다. 뉴런이 활성화되지 않으면 결과값으로 -1을 출력한다.\n",
    "\n",
    "마빈 민스키와 시모어 페퍼트는 저서 \"퍼셉트론\"에서 단층 퍼셉트론은 XOR 연산이 불가능하지만, 다층 퍼셉트론으로는 XOR 연산이 가능함을 보였다.\n",
    "\n",
    "#### 가중치\n",
    "퍼셉트론은 들어오는 연결에 가중치를 할당하여 작동한다. McCulloch-Pitts Neuron을 사용하여 들어오는 연결에서 값의 합계를 구하고 다음 특정 임계 값보다 높거나 낮은 지 확인했다. 내적을 구하는 대신 퍼셉트론을 사용했다. 여기에서는 들어오는 각 값에 가중치를 곱해서 합계를 구했다. \n",
    "`sum: (value1 * weight1) + (value2 * weight2)`\n",
    "\n",
    "## 온라인 학습 Perceptron in Python\n",
    "파이썬으로 위의 퍼셉트론 알고리즘을 구현하며 스크립트가 PyPy(3-4배의 속도 향상)에서 실행되므로 표준 라이브러리를 사용하므로 Kaggle 포럼에서 처음 발견 된 tinrtgu의 온라인 로지스틱 회귀 스크립트에서 큰 영감을 얻었다고 한다. \n",
    "* [Display Advertising Challenge - Kaggle, Beat the benchmark with less then 200MB of memory.](https://www.kaggle.com/c/criteo-display-ad-challenge/discussion/10322)\n",
    "\n",
    "\n",
    "## 온라인 학습\n",
    "퍼셉트론은 온라인 학습이 가능합니다(한 번에 하나씩 샘플을 통해 학습). 메모리에 전체 데이터 세트가 필요하지 않으므로 더 큰 데이터 세트에 유용합니다. 여기에서는 Vowpal Wabbit에서 온라인 학습 코드를 가져왔다.\n",
    "* [Vowpal Wabbit (Fast Learning)](http://hunch.net/~vw/)\n",
    "\n",
    "## 해싱 트릭\n",
    "벡터화 해싱 트릭은 Vowpal Wabbit(John Langford)에서 시작되었다. 이 트릭은 퍼셉트론으로 들어오는 연결 수를 고정 된 크기로 설정한다. 고정 된 크기보다 낮은 숫자로 모든 원시 피처를 해싱한다.\n",
    "\n",
    "\n",
    "\n",
    "* 소스코드 출처\n",
    "    * https://github.com/MLWave/online-learning-perceptron\n",
    "    * https://github.com/MLWave/online-learning-perceptron/blob/master/perceptron.py\n",
    "    * 위 소스코드를 Python3에서 실행되도록 일부 수정하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 코드에서는 pandas, numpy, scipy같은 라이브러리를 사용하지 않고 파이썬에 내장 된 기능만을 사용해 학습하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from math import exp, log\n",
    "from datetime import datetime\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    \"\"\"\n",
    "        Returns a cleaned, lowercased string\n",
    "        텍스트 데이터를 정제하고 소문자로 변환해 준다.\n",
    "    \"\"\"\n",
    "    return \" \".join(re.findall(r'\\w+', s, flags = re.UNICODE)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tsv(loc_dataset,opts):\n",
    "    \"\"\"\n",
    "    Running through data in an online manner\n",
    "    Parses a tsv file for this competition and yields label, identifier and features\n",
    "    output:\n",
    "            label: int, The label / target (set to \"1\" if test set)\n",
    "            id: string, the sample identifier\n",
    "            features: list of tuples, in the form [(hashed_feature_index,feature_value)]\n",
    "            \n",
    "    온라인 학습 방법을 통해 데이터를 실행한다.\n",
    "    tsv파일을 통해 레이블, identifier, 피처(특성)를 파싱한다.\n",
    "    결과물:\n",
    "        label : int, 레이블 / 대상 (테스트 집합 인 경우 \"1\"로 설정)\n",
    "        id : 문자열, 샘플 식별자\n",
    "        features : [(hashed_feature_index, feature_value)] 형식의 튜플 목록\n",
    "    \"\"\"\n",
    "    for e, line in enumerate(open(loc_dataset,\"rb\")):\n",
    "        if e > 0:\n",
    "            r = line.decode('utf-8').strip().split(\"\\t\")\n",
    "            id = r[0]\n",
    "\n",
    "            if opts[\"clean\"]:\n",
    "                try:\n",
    "                    r[2] = clean(r[2])\n",
    "                except:\n",
    "                    r[1] = clean(r[1])\n",
    "\n",
    "            if len(r) == 3: #train set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[2].split()]\n",
    "                label = int(r[1])\n",
    "            else: #test set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[1].split()]\n",
    "                label = 1\n",
    "\n",
    "            if opts[\"2grams\"]:\n",
    "                for i in range(len(features)-1):\n",
    "                    features.append(\n",
    "                        (hash(str(features[i][0])+str(features[i+1][0]))%opts[\"D\"],1))\n",
    "            yield label, id, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(features,weights):\n",
    "    \"\"\"\n",
    "    Calculate dot product from features and weights\n",
    "    input:\n",
    "            features: A list of tuples [(feature_index,feature_value)]\n",
    "            weights: the hashing trick weights filter, note: length is max(feature_index)\n",
    "    output:\n",
    "            dotp: the dot product\n",
    "    피처(특성)과 가중치로부터 내적을 구한다.\n",
    "    \"\"\"\n",
    "    dotp = 0\n",
    "    for f in features:\n",
    "        dotp += weights[f[0]] * f[1]\n",
    "    return dotp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tron(loc_dataset,opts):\n",
    "    start = datetime.now()\n",
    "    print(\"\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "\n",
    "    # 가중치 초기화\n",
    "    if opts[\"random_init\"]:\n",
    "        random.seed(3003)\n",
    "        weights = [random.random()] * opts[\"D\"]\n",
    "    else:\n",
    "        weights = [0.] * opts[\"D\"]\n",
    "\n",
    "    # Running training passes\n",
    "    # 학습 실행\n",
    "    for pass_nr in range(opts[\"n_passes\"]):\n",
    "        error_counter = 0\n",
    "        for e, (label, id, features) in enumerate( get_data_tsv(loc_dataset,opts) ):\n",
    "            \n",
    "            # 퍼셉트론은 지도학습 분류기의 일종이다. \n",
    "            # 이전 값에 대한 학습으로 예측을 한다. \n",
    "            # 내적(dotproduct) 값이 임계 값보다 높거나 낮은지에 따라 \n",
    "            # 초과하면 \"1\"을 예측하고 미만이면 \"0\"을 예측한다.\n",
    "            dp = dot_product(features, weights) > 0.5\n",
    "            \n",
    "            # 다음 perceptron은 샘플의 레이블을 봅니다. \n",
    "            # 예측이 정확하다면, 오류는 \"0\"이며, 가중치만 남겨 둔다. \n",
    "            # 예측이 틀린 경우 오류는 \"-1\"또는 \"1\"이고 퍼셉트론은 다음과 같이 가중치를 업데이트합니다.\n",
    "            # error is 1 if misclassified as 0, error is -1 if misclassified as 1\n",
    "            # weights[feature_index] += learning_rate * error * feature_value\n",
    "            error = label - dp \n",
    "        \n",
    "            if error != 0:\n",
    "                error_counter += 1\n",
    "                # Updating the weights\n",
    "                for index, value in features:\n",
    "                    weights[index] += opts[\"learning_rate\"] * error * log(1.+value)\n",
    "\n",
    "        #Reporting stuff\n",
    "        print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s\" % ( \\\n",
    "            pass_nr+1,\n",
    "            error_counter,\n",
    "            round(1 - error_counter /float(e+1),5),\n",
    "            e+1,datetime.now()-start))\n",
    "\n",
    "        #Oh heh, we have overfit :)\n",
    "        if error_counter == 0 or error_counter < opts[\"errors_satisfied\"]:\n",
    "            print(\"%s errors found during training, halting\"%error_counter)\n",
    "            break\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tron(loc_dataset,opts):\n",
    "    start = datetime.now()\n",
    "    print(\"\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "\n",
    "    #Initializing the weights\n",
    "    if opts[\"random_init\"]:\n",
    "        random.seed(3003)\n",
    "        weights = [random.random()] * opts[\"D\"]\n",
    "    else:\n",
    "        weights = [0.] * opts[\"D\"]\n",
    "\n",
    "    #Running training passes\n",
    "    for pass_nr in range(opts[\"n_passes\"]):\n",
    "        error_counter = 0\n",
    "        for e, (label, id, features) in enumerate( get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "            dp = dot_product(features, weights) > 0.5\n",
    "            error = label - dp # error is 1 if misclassified as 0, error is -1 if misclassified as 1\n",
    "\n",
    "            if error != 0:\n",
    "                error_counter += 1\n",
    "                # Updating the weights\n",
    "                # 가중치 업데이트\n",
    "                for index, value in features:\n",
    "                    weights[index] += opts[\"learning_rate\"] * error * log(1.+value)\n",
    "\n",
    "        # Reporting stuff\n",
    "        print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (\n",
    "            pass_nr+1,\n",
    "            error_counter,\n",
    "            round(1 - error_counter /float(e+1),5),e+1,datetime.now()-start))\n",
    "\n",
    "        # Oh heh, we have overfit :)\n",
    "        # 오버피팅 되면 엄춘다.\n",
    "        if error_counter == 0 or error_counter < opts[\"errors_satisfied\"]:\n",
    "            print(\"%s errors found during training, halting\"%error_counter)\n",
    "            break\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tron(loc_dataset,weights,opts):\n",
    "    \"\"\"\n",
    "        output:\n",
    "                preds: list, a list with [id,prediction,dotproduct,0-1normalized dotproduct]\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    print(\"\\nTesting online\\nErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "    preds = []\n",
    "    error_counter = 0\n",
    "    for e, (label, id, features) in enumerate( get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "        dotp = dot_product(features, weights)\n",
    "        # 내적이 0.5보다 크다면 긍정으로 예측한다.\n",
    "        dp = dotp > 0.5\n",
    "        if dp > 0.5: # we predict positive class\n",
    "            preds.append( [id, 1, dotp ] )\n",
    "        else:\n",
    "            preds.append( [id, 0, dotp ] )\n",
    "\n",
    "        if label - dp != 0:\n",
    "            error_counter += 1\n",
    "\n",
    "    print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (\n",
    "        error_counter,\n",
    "        round(1 - error_counter /float(e+1),5),\n",
    "        e+1,\n",
    "        datetime.now()-start))\n",
    "\n",
    "    # normalizing dotproducts between 0 and 1 \n",
    "    # TODO: proper probability (bounded sigmoid?), online normalization\n",
    "    max_dotp = max(preds,key=itemgetter(2))[2]\n",
    "    min_dotp = min(preds,key=itemgetter(2))[2]\n",
    "    for p in preds:\n",
    "        p.append((p[2]-min_dotp)/float(max_dotp-min_dotp)) #appending normalized to predictions\n",
    "\n",
    "    #Reporting stuff\n",
    "    print(\"Done testing in %s\"%str(datetime.now()-start))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pass\t\tErrors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "1\t\t5662\t\t0.77352\t\t25000\t\t0:00:16.115041\n",
      "2\t\t3142\t\t0.87432\t\t25000\t\t0:00:31.234052\n",
      "3\t\t2304\t\t0.90784\t\t25000\t\t0:00:46.287895\n",
      "4\t\t1743\t\t0.93028\t\t25000\t\t0:01:01.079004\n",
      "5\t\t1237\t\t0.95052\t\t25000\t\t0:01:15.817920\n",
      "6\t\t1037\t\t0.95852\t\t25000\t\t0:01:30.555684\n",
      "7\t\t788\t\t0.96848\t\t25000\t\t0:01:45.169659\n",
      "8\t\t667\t\t0.97332\t\t25000\t\t0:02:00.072391\n",
      "9\t\t484\t\t0.98064\t\t25000\t\t0:02:14.725834\n",
      "10\t\t458\t\t0.98168\t\t25000\t\t0:02:29.367534\n",
      "11\t\t379\t\t0.98484\t\t25000\t\t0:02:44.166580\n",
      "12\t\t381\t\t0.98476\t\t25000\t\t0:02:58.766317\n",
      "13\t\t270\t\t0.9892\t\t25000\t\t0:03:13.331800\n",
      "14\t\t209\t\t0.99164\t\t25000\t\t0:03:27.830063\n",
      "15\t\t214\t\t0.99144\t\t25000\t\t0:03:42.439388\n",
      "16\t\t182\t\t0.99272\t\t25000\t\t0:03:56.961730\n",
      "17\t\t141\t\t0.99436\t\t25000\t\t0:04:11.550386\n",
      "18\t\t155\t\t0.9938\t\t25000\t\t0:04:26.064445\n",
      "19\t\t118\t\t0.99528\t\t25000\t\t0:04:40.758668\n",
      "20\t\t115\t\t0.9954\t\t25000\t\t0:04:55.301637\n",
      "21\t\t134\t\t0.99464\t\t25000\t\t0:05:09.882911\n",
      "22\t\t70\t\t0.9972\t\t25000\t\t0:05:24.386131\n",
      "23\t\t62\t\t0.99752\t\t25000\t\t0:05:38.981252\n",
      "24\t\t37\t\t0.99852\t\t25000\t\t0:05:53.853744\n",
      "25\t\t55\t\t0.9978\t\t25000\t\t0:06:08.478788\n",
      "26\t\t36\t\t0.99856\t\t25000\t\t0:06:23.014501\n",
      "27\t\t29\t\t0.99884\t\t25000\t\t0:06:37.715556\n",
      "28\t\t49\t\t0.99804\t\t25000\t\t0:06:52.317975\n",
      "29\t\t38\t\t0.99848\t\t25000\t\t0:07:07.080348\n",
      "30\t\t11\t\t0.99956\t\t25000\t\t0:07:21.611278\n",
      "31\t\t23\t\t0.99908\t\t25000\t\t0:07:36.235261\n",
      "32\t\t5\t\t0.9998\t\t25000\t\t0:07:50.750880\n",
      "33\t\t0\t\t1.0\t\t25000\t\t0:08:05.333542\n",
      "0 errors found during training, halting\n",
      "CPU times: user 8min 3s, sys: 863 ms, total: 8min 4s\n",
      "Wall time: 8min 5s\n"
     ]
    }
   ],
   "source": [
    "#Setting options\n",
    "opts = {}\n",
    "opts[\"D\"] = 2 ** 25\n",
    "opts[\"learning_rate\"] = 0.1\n",
    "opts[\"n_passes\"] = 80 # Maximum number of passes to run before halting\n",
    "opts[\"errors_satisfied\"] = 0 # Halt when training errors < errors_satisfied\n",
    "opts[\"random_init\"] = False # set random weights, else set all 0\n",
    "opts[\"clean\"] = True # clean the text a little\n",
    "opts[\"2grams\"] = True # add 2grams\n",
    "\n",
    "#training and saving model into weights\n",
    "%time weights = train_tron(\"data/labeledTrainData.tsv\",opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing online\n",
      "Errors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "12849\t\t0.48604\t\t25000\t\t0:00:14.563494\n",
      "Done testing in 0:00:14.581813\n",
      "CPU times: user 14.5 s, sys: 39.3 ms, total: 14.5 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "#testing and saving predictions into preds\n",
    "%time preds = test_tron(\"data/testData.tsv\",weights,opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing kaggle submission\n",
    "with open(\"data/submit_perceptron.csv\",\"wb\") as outfile:\n",
    "    outfile.write('\"id\",\"sentiment\"\\n'.encode('utf-8'))\n",
    "    for p in sorted(preds):\n",
    "        outfile.write(\"{},{}\\n\".format(p[0],p[3]).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2231833910034602"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 캐글 스코어 0.95338\n",
    "129/578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 상위 벤치 마크\n",
    "포럼에서 현재 가장 좋은 벤치 마크 는 Abhishek 의 로지스틱 회귀 스크립트다. 리더 보드에서 0.95 AUC 를 얻기 위해 학습과 테스트 세트의 메모리 안에서 tfidf-fit_transform을 사용한다. 여기에서는 이 변환을 건너 뛰고 온라인 해시 벡터 라이저를 사용한다.\n",
    "\n",
    "Abhishek의 스크립트처럼 기능에서 2g(\"좋지 않은\"등)을 생성한다. 2-gram을 단순히 해쉬하고 샘플 벡터에 추가한다.\n",
    "\n",
    "또, 문자를 소문자로 바꾸고 영숫자가 아닌 것을 제거함으로써 텍스트를 조금 더 빠르게 정제한다.\n",
    "\n",
    "### 예측\n",
    "AUC를 최적화하기 위해 \"1\"또는 \"0\"예측만 제출하지 않는다. 이것은 약 0.88의 AUC를 줄 것이다. 여기에서는 0과 1 사이에서 정규화 된 dotproduct를 제출한다.\n",
    "\n",
    "이 스크립트는 Abhishek의 솔루션 0.952 점수와 비교해 본다. 하지만 이 코드는 단지 몇 MB의 메모리를 필요로하며, tfidf 변환을 수행하지 않고 단지 2분 만에 0의 학습오류에 수렴한다다.\n",
    "\n",
    "텍스트 정제와 2-gram이 없으면 스크립트는 60초 이내에 실행되고 0.93의 점수를 산출한다.\n",
    "\n",
    "\n",
    "## 결론\n",
    "\"절대적인 지식은 없다. 모든 것은 확률에 의해서만 이루어진다 \" - Gödel (1961)\n",
    "\n",
    "0-1 임계 값 활성화가 적용된 매우 기본적인 퍼셉트론은 NLP 경진대회에서 잘 동작한다. 여기에서는 1957 알고리즘을 전혀 변경하지 않았다. 해싱 트릭을 없애고 비슷하거나 약간 더 좋은 점수를 받을 수 있다.\n",
    "\n",
    "이 스크립트는 확률을 출력 할 수 없다. dotproduct에 bounded sigmoid를 사용하여 출력의 온라인 정규화 형태를 얻거나 tinrtgu의 스크립트를 더 보완해 볼 수 있을 것이다.\n",
    "\n",
    "단일 노드 단일 레이어 퍼셉트론은 비선형 함수를 모델링 할 수 없으므로 더 나은 NLP 결과를 얻으려면 FFN(feedforward nets), recurrent nets, self-organizing maps, MLP(Multi-layer Perceptrons), word2vec 및 extreme learning machine (백프로파게이션이 없는 fast ffnets)을 봐야할 것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
